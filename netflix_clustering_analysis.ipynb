{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9b20b8b",
   "metadata": {},
   "source": [
    "# Netflix Show Clustering Analysis\n",
    "\n",
    "This notebook demonstrates K-Means clustering to group similar Netflix shows based on genre, rating, and duration.\n",
    "\n",
    "## Project Overview\n",
    "- **Objective**: Group similar Netflix shows using unsupervised machine learning\n",
    "- **Algorithm**: K-Means Clustering\n",
    "- **Features**: Genre, Rating, Duration, Type, Year, Seasons\n",
    "- **Tech Stack**: Python, Pandas, Scikit-learn, Seaborn, Matplotlib\n",
    "\n",
    "## Dataset\n",
    "We'll analyze a curated dataset of Netflix shows and movies with features including:\n",
    "- **Title**: Name of the show/movie\n",
    "- **Genre**: Content category (Action, Drama, Comedy, etc.)\n",
    "- **Rating**: IMDb rating (1-10 scale)\n",
    "- **Duration**: Length in minutes\n",
    "- **Type**: Movie or TV Show\n",
    "- **Year**: Release year\n",
    "- **Seasons**: Number of seasons (for TV shows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c93139",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e65dc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries for data manipulation, clustering, and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"âœ… All libraries imported successfully!\")\n",
    "print(\"ğŸ“š Libraries loaded:\")\n",
    "print(\"   - Pandas for data manipulation\")\n",
    "print(\"   - NumPy for numerical operations\") \n",
    "print(\"   - Matplotlib & Seaborn for visualization\")\n",
    "print(\"   - Scikit-learn for machine learning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68a37c7",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Netflix Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd695592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Netflix dataset\n",
    "df = pd.read_csv('netflix_shows.csv')\n",
    "\n",
    "print(\"ğŸ“Š Dataset Overview:\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(\"\\nğŸ“‹ Data Types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nğŸ” Missing Values:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nğŸ“ˆ Basic Statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21192888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows of the dataset\n",
    "print(\"ğŸ¬ Sample Netflix Shows:\")\n",
    "print(\"=\"*80)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b7bfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data Analysis - Visualizations\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('ğŸ¬ Netflix Shows - Exploratory Data Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Rating distribution\n",
    "axes[0, 0].hist(df['rating'], bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0, 0].set_title('Rating Distribution')\n",
    "axes[0, 0].set_xlabel('Rating')\n",
    "axes[0, 0].set_ylabel('Count')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Duration distribution\n",
    "axes[0, 1].hist(df['duration'], bins=20, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "axes[0, 1].set_title('Duration Distribution')\n",
    "axes[0, 1].set_xlabel('Duration (minutes)')\n",
    "axes[0, 1].set_ylabel('Count')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Genre distribution\n",
    "genre_counts = df['genre'].value_counts()\n",
    "axes[0, 2].bar(range(len(genre_counts)), genre_counts.values, color='coral', alpha=0.8)\n",
    "axes[0, 2].set_title('Genre Distribution')\n",
    "axes[0, 2].set_xlabel('Genre')\n",
    "axes[0, 2].set_ylabel('Count')\n",
    "axes[0, 2].set_xticks(range(len(genre_counts)))\n",
    "axes[0, 2].set_xticklabels(genre_counts.index, rotation=45, ha='right')\n",
    "\n",
    "# 4. Rating vs Duration scatter plot\n",
    "colors = ['red' if t == 'Movie' else 'blue' for t in df['type']]\n",
    "axes[1, 0].scatter(df['duration'], df['rating'], c=colors, alpha=0.7, s=50)\n",
    "axes[1, 0].set_title('Rating vs Duration')\n",
    "axes[1, 0].set_xlabel('Duration (minutes)')\n",
    "axes[1, 0].set_ylabel('Rating')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "# Create custom legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [Patch(facecolor='red', label='Movie'),\n",
    "                  Patch(facecolor='blue', label='TV Show')]\n",
    "axes[1, 0].legend(handles=legend_elements)\n",
    "\n",
    "# 5. Year distribution\n",
    "axes[1, 1].hist(df['year'], bins=15, alpha=0.7, color='gold', edgecolor='black')\n",
    "axes[1, 1].set_title('Release Year Distribution')\n",
    "axes[1, 1].set_xlabel('Year')\n",
    "axes[1, 1].set_ylabel('Count')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Type distribution\n",
    "type_counts = df['type'].value_counts()\n",
    "axes[1, 2].pie(type_counts.values, labels=type_counts.index, autopct='%1.1f%%', \n",
    "               colors=['lightcoral', 'lightblue'])\n",
    "axes[1, 2].set_title('Content Type Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print genre and type distributions\n",
    "print(\"\\nğŸ“Š Content Distribution:\")\n",
    "print(\"Genre counts:\")\n",
    "for genre, count in df['genre'].value_counts().items():\n",
    "    print(f\"  {genre}: {count}\")\n",
    "\n",
    "print(f\"\\nType counts:\")\n",
    "for content_type, count in df['type'].value_counts().items():\n",
    "    print(f\"  {content_type}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ba34cb",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e406be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for preprocessing\n",
    "df_processed = df.copy()\n",
    "\n",
    "# Initialize label encoders\n",
    "label_encoders = {}\n",
    "\n",
    "# Encode categorical variables\n",
    "categorical_cols = ['genre', 'type', 'country']\n",
    "\n",
    "print(\"ğŸ”„ Encoding categorical variables:\")\n",
    "for col in categorical_cols:\n",
    "    if col in df_processed.columns:\n",
    "        le = LabelEncoder()\n",
    "        df_processed[f'{col}_encoded'] = le.fit_transform(df_processed[col])\n",
    "        label_encoders[col] = le\n",
    "        \n",
    "        # Create mapping dictionary\n",
    "        mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "        print(f\"  {col}: {mapping}\")\n",
    "\n",
    "# Check for missing values and handle if necessary\n",
    "print(f\"\\nğŸ” Missing values after preprocessing:\")\n",
    "print(df_processed.isnull().sum())\n",
    "\n",
    "# If there are missing values, fill them\n",
    "if df_processed.isnull().sum().sum() > 0:\n",
    "    print(\"âš ï¸ Handling missing values...\")\n",
    "    df_processed = df_processed.fillna(df_processed.mean(numeric_only=True))\n",
    "    print(\"âœ… Missing values handled\")\n",
    "\n",
    "print(f\"\\nâœ… Preprocessing completed!\")\n",
    "print(f\"Original features: {list(df.columns)}\")\n",
    "print(f\"Processed features: {list(df_processed.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b937218",
   "metadata": {},
   "source": [
    "## 4. Feature Scaling and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2b6bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for clustering\n",
    "clustering_features = ['rating', 'duration', 'genre_encoded', 'type_encoded', 'year', 'seasons']\n",
    "\n",
    "# Ensure all features exist in the dataframe\n",
    "available_features = [f for f in clustering_features if f in df_processed.columns]\n",
    "print(f\"ğŸ¯ Selected features for clustering: {available_features}\")\n",
    "\n",
    "# Create feature matrix\n",
    "X = df_processed[available_features].copy()\n",
    "\n",
    "print(f\"\\nğŸ“Š Feature matrix before scaling:\")\n",
    "print(X.describe())\n",
    "\n",
    "# Scale the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=available_features)\n",
    "\n",
    "print(f\"\\nâš–ï¸ Feature matrix after scaling:\")\n",
    "print(X_scaled_df.describe())\n",
    "\n",
    "print(f\"\\nâœ… Feature scaling completed!\")\n",
    "print(f\"Feature matrix shape: {X_scaled_df.shape}\")\n",
    "\n",
    "# Visualize the scaled features\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "X.boxplot()\n",
    "plt.title('Features Before Scaling')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "X_scaled_df.boxplot()\n",
    "plt.title('Features After Scaling')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e8686c",
   "metadata": {},
   "source": [
    "## 5. Determine Optimal Number of Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362fbe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Elbow Method and Silhouette Analysis to find optimal clusters\n",
    "max_clusters = 10\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "K_range = range(2, max_clusters + 1)\n",
    "\n",
    "print(\"ğŸ” Finding optimal number of clusters...\")\n",
    "print(\"K\\tInertia\\t\\tSilhouette Score\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for k in K_range:\n",
    "    # Fit K-Means\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    cluster_labels = kmeans.fit_predict(X_scaled)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    inertia = kmeans.inertia_\n",
    "    sil_score = silhouette_score(X_scaled, cluster_labels)\n",
    "    \n",
    "    inertias.append(inertia)\n",
    "    silhouette_scores.append(sil_score)\n",
    "    \n",
    "    print(f\"{k}\\t{inertia:.2f}\\t\\t{sil_score:.3f}\")\n",
    "\n",
    "# Find optimal k using silhouette score\n",
    "optimal_k = K_range[np.argmax(silhouette_scores)]\n",
    "print(f\"\\nğŸ¯ Optimal number of clusters: {optimal_k} (highest silhouette score)\")\n",
    "\n",
    "# Create visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Elbow Method Plot\n",
    "ax1.plot(K_range, inertias, 'bo-', linewidth=2, markersize=8)\n",
    "ax1.set_xlabel('Number of Clusters (k)')\n",
    "ax1.set_ylabel('Inertia (Within-cluster Sum of Squares)')\n",
    "ax1.set_title('ğŸ“ˆ Elbow Method for Optimal k')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.axvline(x=optimal_k, color='red', linestyle='--', alpha=0.8,\n",
    "           label=f'Optimal k = {optimal_k}')\n",
    "ax1.legend()\n",
    "\n",
    "# Silhouette Score Plot\n",
    "ax2.plot(K_range, silhouette_scores, 'ro-', linewidth=2, markersize=8)\n",
    "ax2.set_xlabel('Number of Clusters (k)')\n",
    "ax2.set_ylabel('Silhouette Score')\n",
    "ax2.set_title('ğŸ“Š Silhouette Analysis')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.axvline(x=optimal_k, color='red', linestyle='--', alpha=0.8,\n",
    "           label=f'Optimal k = {optimal_k}')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nğŸ“‹ Analysis Summary:\")\n",
    "print(f\"   â€¢ Optimal clusters: {optimal_k}\")\n",
    "print(f\"   â€¢ Best silhouette score: {max(silhouette_scores):.3f}\")\n",
    "print(f\"   â€¢ Corresponding inertia: {inertias[optimal_k-2]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3d57de",
   "metadata": {},
   "source": [
    "## 6. Apply K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd177f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply K-Means with optimal number of clusters\n",
    "final_kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "cluster_labels = final_kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Add cluster labels to the processed dataframe\n",
    "df_processed['cluster'] = cluster_labels\n",
    "\n",
    "# Calculate final metrics\n",
    "final_inertia = final_kmeans.inertia_\n",
    "final_silhouette = silhouette_score(X_scaled, cluster_labels)\n",
    "\n",
    "print(\"ğŸ¯ K-Means Clustering Results:\")\n",
    "print(f\"   â€¢ Number of clusters: {optimal_k}\")\n",
    "print(f\"   â€¢ Final inertia: {final_inertia:.2f}\")\n",
    "print(f\"   â€¢ Final silhouette score: {final_silhouette:.3f}\")\n",
    "\n",
    "# Display cluster distribution\n",
    "cluster_distribution = df_processed['cluster'].value_counts().sort_index()\n",
    "print(f\"\\nğŸ“Š Cluster Distribution:\")\n",
    "for cluster_id, count in cluster_distribution.items():\n",
    "    percentage = (count / len(df_processed)) * 100\n",
    "    print(f\"   Cluster {cluster_id}: {count} shows ({percentage:.1f}%)\")\n",
    "\n",
    "# Create a summary table\n",
    "print(f\"\\nğŸ“‹ Cluster Summary:\")\n",
    "summary_stats = df_processed.groupby('cluster').agg({\n",
    "    'rating': ['mean', 'std'],\n",
    "    'duration': ['mean', 'std'],\n",
    "    'year': ['min', 'max'],\n",
    "    'seasons': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "print(summary_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2211dc8f",
   "metadata": {},
   "source": [
    "## 7. Visualize Clustering Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c076cf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualizations\n",
    "fig = plt.figure(figsize=(20, 15))\n",
    "\n",
    "# 1. PCA visualization for 2D representation\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "ax1 = plt.subplot(2, 3, 1)\n",
    "scatter = ax1.scatter(X_pca[:, 0], X_pca[:, 1], \n",
    "                     c=df_processed['cluster'], \n",
    "                     cmap='tab10', alpha=0.7, s=60)\n",
    "ax1.set_title('ğŸ¯ Clusters in PCA Space')\n",
    "ax1.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)')\n",
    "ax1.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "plt.colorbar(scatter, ax=ax1, label='Cluster')\n",
    "\n",
    "# 2. Rating vs Duration scatter plot\n",
    "ax2 = plt.subplot(2, 3, 2)\n",
    "scatter2 = ax2.scatter(df_processed['duration'], df_processed['rating'], \n",
    "                      c=df_processed['cluster'], cmap='tab10', alpha=0.7, s=60)\n",
    "ax2.set_title('ğŸ“Š Rating vs Duration (Clustered)')\n",
    "ax2.set_xlabel('Duration (minutes)')\n",
    "ax2.set_ylabel('Rating')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "plt.colorbar(scatter2, ax=ax2, label='Cluster')\n",
    "\n",
    "# 3. Cluster size distribution\n",
    "ax3 = plt.subplot(2, 3, 3)\n",
    "cluster_counts = df_processed['cluster'].value_counts().sort_index()\n",
    "bars = ax3.bar(cluster_counts.index, cluster_counts.values, \n",
    "              color=plt.cm.tab10(np.linspace(0, 1, len(cluster_counts))), alpha=0.8)\n",
    "ax3.set_title('ğŸ“ˆ Cluster Size Distribution')\n",
    "ax3.set_xlabel('Cluster')\n",
    "ax3.set_ylabel('Number of Shows')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{int(height)}', ha='center', va='bottom')\n",
    "\n",
    "# 4. Average rating by cluster\n",
    "ax4 = plt.subplot(2, 3, 4)\n",
    "avg_rating = df_processed.groupby('cluster')['rating'].mean()\n",
    "bars4 = ax4.bar(avg_rating.index, avg_rating.values,\n",
    "               color=plt.cm.tab10(np.linspace(0, 1, len(avg_rating))), alpha=0.8)\n",
    "ax4.set_title('â­ Average Rating by Cluster')\n",
    "ax4.set_xlabel('Cluster')\n",
    "ax4.set_ylabel('Average Rating')\n",
    "ax4.set_ylim(0, 10)\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars4:\n",
    "    height = bar.get_height()\n",
    "    ax4.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{height:.1f}', ha='center', va='bottom')\n",
    "\n",
    "# 5. Genre distribution by cluster\n",
    "ax5 = plt.subplot(2, 3, 5)\n",
    "genre_cluster = pd.crosstab(df_processed['cluster'], df_processed['genre'])\n",
    "genre_cluster.plot(kind='bar', stacked=True, ax=ax5, colormap='Set3')\n",
    "ax5.set_title('ğŸ­ Genre Distribution by Cluster')\n",
    "ax5.set_xlabel('Cluster')\n",
    "ax5.set_ylabel('Count')\n",
    "ax5.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax5.grid(True, alpha=0.3)\n",
    "plt.setp(ax5.xaxis.get_majorticklabels(), rotation=0)\n",
    "\n",
    "# 6. Type distribution by cluster\n",
    "ax6 = plt.subplot(2, 3, 6)\n",
    "type_cluster = pd.crosstab(df_processed['cluster'], df_processed['type'])\n",
    "type_cluster.plot(kind='bar', ax=ax6, colormap='Set2', alpha=0.8)\n",
    "ax6.set_title('ğŸ“º Type Distribution by Cluster')\n",
    "ax6.set_xlabel('Cluster')\n",
    "ax6.set_ylabel('Count')\n",
    "ax6.legend()\n",
    "ax6.grid(True, alpha=0.3)\n",
    "plt.setp(ax6.xaxis.get_majorticklabels(), rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ğŸ¨ All visualizations completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600b3c89",
   "metadata": {},
   "source": [
    "## 8. Analyze Cluster Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e144805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed analysis of each cluster\n",
    "n_clusters = len(df_processed['cluster'].unique())\n",
    "\n",
    "print(\"ğŸ” DETAILED CLUSTER ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for cluster_id in sorted(df_processed['cluster'].unique()):\n",
    "    cluster_data = df_processed[df_processed['cluster'] == cluster_id]\n",
    "    \n",
    "    print(f\"\\nğŸ¯ CLUSTER {cluster_id} ANALYSIS\")\n",
    "    print(f\"{'=' * 30}\")\n",
    "    print(f\"ğŸ“Š Size: {len(cluster_data)} shows ({len(cluster_data)/len(df_processed)*100:.1f}%)\")\n",
    "    \n",
    "    # Statistical summary\n",
    "    print(f\"\\nğŸ“ˆ Statistical Summary:\")\n",
    "    print(f\"   â€¢ Average Rating: {cluster_data['rating'].mean():.2f} (Â±{cluster_data['rating'].std():.2f})\")\n",
    "    print(f\"   â€¢ Average Duration: {cluster_data['duration'].mean():.1f} minutes (Â±{cluster_data['duration'].std():.1f})\")\n",
    "    print(f\"   â€¢ Year Range: {cluster_data['year'].min()} - {cluster_data['year'].max()}\")\n",
    "    print(f\"   â€¢ Average Seasons: {cluster_data['seasons'].mean():.1f}\")\n",
    "    \n",
    "    # Most common characteristics\n",
    "    print(f\"\\nğŸ·ï¸ Most Common Characteristics:\")\n",
    "    most_common_genre = cluster_data['genre'].mode()\n",
    "    most_common_type = cluster_data['type'].mode()\n",
    "    most_common_country = cluster_data['country'].mode()\n",
    "    \n",
    "    print(f\"   â€¢ Genre: {most_common_genre.iloc[0] if len(most_common_genre) > 0 else 'N/A'}\")\n",
    "    print(f\"   â€¢ Type: {most_common_type.iloc[0] if len(most_common_type) > 0 else 'N/A'}\")\n",
    "    print(f\"   â€¢ Country: {most_common_country.iloc[0] if len(most_common_country) > 0 else 'N/A'}\")\n",
    "    \n",
    "    # Genre distribution in this cluster\n",
    "    print(f\"\\nğŸ­ Genre Distribution:\")\n",
    "    genre_dist = cluster_data['genre'].value_counts()\n",
    "    for genre, count in genre_dist.head().items():\n",
    "        percentage = (count / len(cluster_data)) * 100\n",
    "        print(f\"   â€¢ {genre}: {count} shows ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Sample shows from this cluster\n",
    "    print(f\"\\nğŸ¬ Sample Shows:\")\n",
    "    sample_shows = cluster_data[['title', 'genre', 'rating', 'duration', 'type']].head(5)\n",
    "    for _, show in sample_shows.iterrows():\n",
    "        print(f\"   â€¢ {show['title']} ({show['genre']}, {show['type']}) - â­{show['rating']}, {show['duration']}min\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34c7859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate key insights and business recommendations\n",
    "print(\"ğŸ’¡ KEY INSIGHTS & BUSINESS RECOMMENDATIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "insights = []\n",
    "\n",
    "# Clustering quality assessment\n",
    "if final_silhouette > 0.5:\n",
    "    insights.append(\"âœ… Excellent clustering quality - clear separation between clusters\")\n",
    "elif final_silhouette > 0.3:\n",
    "    insights.append(\"ğŸ“Š Good clustering quality - meaningful groupings identified\")\n",
    "else:\n",
    "    insights.append(\"âš ï¸ Moderate clustering quality - consider feature engineering\")\n",
    "\n",
    "# Cluster balance\n",
    "max_size = cluster_distribution.max()\n",
    "min_size = cluster_distribution.min()\n",
    "if max_size / min_size <= 3:\n",
    "    insights.append(\"âš–ï¸ Well-balanced cluster sizes\")\n",
    "else:\n",
    "    insights.append(\"ğŸ“ Some clusters are significantly larger than others\")\n",
    "\n",
    "# Content type separation\n",
    "type_analysis = pd.crosstab(df_processed['cluster'], df_processed['type'])\n",
    "for cluster_id in type_analysis.index:\n",
    "    movies = type_analysis.loc[cluster_id, 'Movie'] if 'Movie' in type_analysis.columns else 0\n",
    "    tv_shows = type_analysis.loc[cluster_id, 'TV Show'] if 'TV Show' in type_analysis.columns else 0\n",
    "    total = movies + tv_shows\n",
    "    \n",
    "    if total > 0:\n",
    "        movie_pct = movies / total\n",
    "        if movie_pct >= 0.8:\n",
    "            insights.append(f\"ğŸ¬ Cluster {cluster_id} is primarily Movies ({movie_pct:.1%})\")\n",
    "        elif movie_pct <= 0.2:\n",
    "            insights.append(f\"ğŸ“º Cluster {cluster_id} is primarily TV Shows ({1-movie_pct:.1%})\")\n",
    "\n",
    "print(\"\\nğŸ“‹ INSIGHTS:\")\n",
    "for i, insight in enumerate(insights, 1):\n",
    "    print(f\"{i}. {insight}\")\n",
    "\n",
    "print(f\"\\nğŸš€ BUSINESS RECOMMENDATIONS:\")\n",
    "recommendations = [\n",
    "    \"ğŸ¯ Use clusters for personalized content recommendations\",\n",
    "    \"ğŸ“ˆ Optimize content acquisition based on cluster preferences\", \n",
    "    \"ğŸª Create targeted marketing campaigns for each cluster\",\n",
    "    \"ğŸ“Š Analyze viewing patterns within clusters for content planning\",\n",
    "    \"ğŸŒŸ Develop cluster-specific user interface experiences\",\n",
    "    \"ğŸ“º Plan content production based on successful cluster patterns\",\n",
    "    \"ğŸ” Monitor cluster evolution over time for trend analysis\"\n",
    "]\n",
    "\n",
    "for i, rec in enumerate(recommendations, 1):\n",
    "    print(f\"{i}. {rec}\")\n",
    "\n",
    "print(f\"\\nğŸ“Š CLUSTERING PERFORMANCE SUMMARY:\")\n",
    "print(f\"   â€¢ Optimal Clusters: {optimal_k}\")\n",
    "print(f\"   â€¢ Silhouette Score: {final_silhouette:.3f}\")\n",
    "print(f\"   â€¢ Inertia: {final_inertia:.2f}\")\n",
    "print(f\"   â€¢ Total Shows Analyzed: {len(df_processed)}\")\n",
    "print(f\"   â€¢ Features Used: {len(available_features)}\")\n",
    "\n",
    "print(f\"\\nğŸ‰ Analysis Complete! Netflix shows successfully clustered into {optimal_k} meaningful groups.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
